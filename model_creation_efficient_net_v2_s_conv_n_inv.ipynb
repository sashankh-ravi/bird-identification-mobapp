{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sashankhravi/miniconda3/envs/birdapp1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from timm.models.efficientnet import efficientnetv2_s\n",
    "from nn_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check torch summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sashankhravi/miniconda3/envs/birdapp1/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Identity-1          [-1, 3, 224, 224]               0\n",
      "          Identity-2          [-1, 3, 224, 224]               0\n",
      "          Identity-3          [-1, 3, 224, 224]               0\n",
      "              SiLU-4                    [-1, 9]               0\n",
      "              SiLU-5                    [-1, 9]               0\n",
      "              SiLU-6                    [-1, 9]               0\n",
      "              SiLU-7                    [-1, 9]               0\n",
      "              SiLU-8                    [-1, 9]               0\n",
      "              SiLU-9                    [-1, 9]               0\n",
      "             SiLU-10                    [-1, 9]               0\n",
      "             SiLU-11                    [-1, 9]               0\n",
      "             SiLU-12                    [-1, 9]               0\n",
      "KAN_Convolutional_Layer-13          [-1, 3, 112, 112]               0\n",
      "      BatchNorm2d-14          [-1, 3, 112, 112]               6\n",
      "           Unfold-15            [-1, 27, 12544]               0\n",
      "           Conv2d-16          [-1, 1, 112, 112]               4\n",
      "      BatchNorm2d-17          [-1, 1, 112, 112]               2\n",
      "             ReLU-18          [-1, 1, 112, 112]               0\n",
      "           Conv2d-19          [-1, 9, 112, 112]              18\n",
      "           Conv2d-20         [-1, 24, 112, 112]              96\n",
      "       Involution-21         [-1, 24, 112, 112]               0\n",
      "      BatchNorm2d-22         [-1, 24, 112, 112]              48\n",
      "             SiLU-23         [-1, 24, 112, 112]               0\n",
      "ConvInvolutionBlock-24         [-1, 24, 112, 112]               0\n",
      "           Conv2d-25         [-1, 96, 112, 112]           2,400\n",
      "      BatchNorm2d-26         [-1, 96, 112, 112]             192\n",
      "             SiLU-27         [-1, 96, 112, 112]               0\n",
      "KAN_Convolutional_Layer-28           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-29           [-1, 96, 56, 56]             192\n",
      "           Unfold-30            [-1, 864, 3136]               0\n",
      "           Conv2d-31           [-1, 48, 56, 56]           4,656\n",
      "      BatchNorm2d-32           [-1, 48, 56, 56]              96\n",
      "             ReLU-33           [-1, 48, 56, 56]               0\n",
      "           Conv2d-34            [-1, 9, 56, 56]             441\n",
      "           Conv2d-35           [-1, 48, 56, 56]           4,656\n",
      "       Involution-36           [-1, 48, 56, 56]               0\n",
      "      BatchNorm2d-37           [-1, 48, 56, 56]              96\n",
      "             SiLU-38           [-1, 48, 56, 56]               0\n",
      "ConvInvolutionBlock-39           [-1, 48, 56, 56]               0\n",
      "           Conv2d-40          [-1, 192, 56, 56]           9,408\n",
      "      BatchNorm2d-41          [-1, 192, 56, 56]             384\n",
      "             SiLU-42          [-1, 192, 56, 56]               0\n",
      "KAN_Convolutional_Layer-43          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-44          [-1, 192, 28, 28]             384\n",
      "           Unfold-45            [-1, 1728, 784]               0\n",
      "           Conv2d-46           [-1, 96, 28, 28]          18,528\n",
      "      BatchNorm2d-47           [-1, 96, 28, 28]             192\n",
      "             ReLU-48           [-1, 96, 28, 28]               0\n",
      "           Conv2d-49            [-1, 9, 28, 28]             873\n",
      "           Conv2d-50           [-1, 48, 28, 28]           9,264\n",
      "       Involution-51           [-1, 48, 28, 28]               0\n",
      "      BatchNorm2d-52           [-1, 48, 28, 28]              96\n",
      "             SiLU-53           [-1, 48, 28, 28]               0\n",
      "ConvInvolutionBlock-54           [-1, 48, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           9,408\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "             SiLU-57          [-1, 192, 28, 28]               0\n",
      "KAN_Convolutional_Layer-58          [-1, 192, 14, 14]               0\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "           Unfold-60            [-1, 1728, 196]               0\n",
      "           Conv2d-61           [-1, 96, 14, 14]          18,528\n",
      "      BatchNorm2d-62           [-1, 96, 14, 14]             192\n",
      "             ReLU-63           [-1, 96, 14, 14]               0\n",
      "           Conv2d-64            [-1, 9, 14, 14]             873\n",
      "           Conv2d-65           [-1, 48, 14, 14]           9,264\n",
      "       Involution-66           [-1, 48, 14, 14]               0\n",
      "      BatchNorm2d-67           [-1, 48, 14, 14]              96\n",
      "             SiLU-68           [-1, 48, 14, 14]               0\n",
      "ConvInvolutionBlock-69           [-1, 48, 14, 14]               0\n",
      "           Conv2d-70          [-1, 192, 14, 14]           9,408\n",
      "      BatchNorm2d-71          [-1, 192, 14, 14]             384\n",
      "             SiLU-72          [-1, 192, 14, 14]               0\n",
      "KAN_Convolutional_Layer-73            [-1, 192, 7, 7]               0\n",
      "      BatchNorm2d-74            [-1, 192, 7, 7]             384\n",
      "           Unfold-75             [-1, 1728, 49]               0\n",
      "           Conv2d-76             [-1, 96, 7, 7]          18,528\n",
      "      BatchNorm2d-77             [-1, 96, 7, 7]             192\n",
      "             ReLU-78             [-1, 96, 7, 7]               0\n",
      "           Conv2d-79              [-1, 9, 7, 7]             873\n",
      "           Conv2d-80             [-1, 48, 7, 7]           9,264\n",
      "       Involution-81             [-1, 48, 7, 7]               0\n",
      "      BatchNorm2d-82             [-1, 48, 7, 7]              96\n",
      "             SiLU-83             [-1, 48, 7, 7]               0\n",
      "ConvInvolutionBlock-84             [-1, 48, 7, 7]               0\n",
      "           Conv2d-85            [-1, 192, 7, 7]           9,408\n",
      "      BatchNorm2d-86            [-1, 192, 7, 7]             384\n",
      "             SiLU-87            [-1, 192, 7, 7]               0\n",
      "KAN_Convolutional_Layer-88            [-1, 192, 4, 4]               0\n",
      "      BatchNorm2d-89            [-1, 192, 4, 4]             384\n",
      "           Unfold-90             [-1, 1728, 16]               0\n",
      "           Conv2d-91             [-1, 96, 4, 4]          18,528\n",
      "      BatchNorm2d-92             [-1, 96, 4, 4]             192\n",
      "             ReLU-93             [-1, 96, 4, 4]               0\n",
      "           Conv2d-94              [-1, 9, 4, 4]             873\n",
      "           Conv2d-95             [-1, 48, 4, 4]           9,264\n",
      "       Involution-96             [-1, 48, 4, 4]               0\n",
      "      BatchNorm2d-97             [-1, 48, 4, 4]              96\n",
      "             SiLU-98             [-1, 48, 4, 4]               0\n",
      "ConvInvolutionBlock-99             [-1, 48, 4, 4]               0\n",
      "          MBConv-100             [-1, 48, 4, 4]               0\n",
      "          Conv2d-101            [-1, 192, 4, 4]           9,408\n",
      "     BatchNorm2d-102            [-1, 192, 4, 4]             384\n",
      "            SiLU-103            [-1, 192, 4, 4]               0\n",
      "KAN_Convolutional_Layer-104            [-1, 192, 2, 2]               0\n",
      "     BatchNorm2d-105            [-1, 192, 2, 2]             384\n",
      "          Unfold-106              [-1, 1728, 4]               0\n",
      "          Conv2d-107             [-1, 96, 2, 2]          18,528\n",
      "     BatchNorm2d-108             [-1, 96, 2, 2]             192\n",
      "            ReLU-109             [-1, 96, 2, 2]               0\n",
      "          Conv2d-110              [-1, 9, 2, 2]             873\n",
      "          Conv2d-111             [-1, 64, 2, 2]          12,352\n",
      "      Involution-112             [-1, 64, 2, 2]               0\n",
      "     BatchNorm2d-113             [-1, 64, 2, 2]             128\n",
      "            SiLU-114             [-1, 64, 2, 2]               0\n",
      "ConvInvolutionBlock-115             [-1, 64, 2, 2]               0\n",
      "          Conv2d-116            [-1, 256, 2, 2]          16,640\n",
      "     BatchNorm2d-117            [-1, 256, 2, 2]             512\n",
      "            SiLU-118            [-1, 256, 2, 2]               0\n",
      "KAN_Convolutional_Layer-119            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-120            [-1, 256, 1, 1]             512\n",
      "          Unfold-121              [-1, 2304, 1]               0\n",
      "          Conv2d-122            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-123            [-1, 128, 1, 1]             256\n",
      "            ReLU-124            [-1, 128, 1, 1]               0\n",
      "          Conv2d-125              [-1, 9, 1, 1]           1,161\n",
      "          Conv2d-126             [-1, 64, 1, 1]          16,448\n",
      "      Involution-127             [-1, 64, 1, 1]               0\n",
      "     BatchNorm2d-128             [-1, 64, 1, 1]             128\n",
      "            SiLU-129             [-1, 64, 1, 1]               0\n",
      "ConvInvolutionBlock-130             [-1, 64, 1, 1]               0\n",
      "          Conv2d-131            [-1, 256, 1, 1]          16,640\n",
      "     BatchNorm2d-132            [-1, 256, 1, 1]             512\n",
      "            SiLU-133            [-1, 256, 1, 1]               0\n",
      "KAN_Convolutional_Layer-134            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-135            [-1, 256, 1, 1]             512\n",
      "          Unfold-136              [-1, 2304, 1]               0\n",
      "          Conv2d-137            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-138            [-1, 128, 1, 1]             256\n",
      "            ReLU-139            [-1, 128, 1, 1]               0\n",
      "          Conv2d-140              [-1, 9, 1, 1]           1,161\n",
      "          Conv2d-141             [-1, 64, 1, 1]          16,448\n",
      "      Involution-142             [-1, 64, 1, 1]               0\n",
      "     BatchNorm2d-143             [-1, 64, 1, 1]             128\n",
      "            SiLU-144             [-1, 64, 1, 1]               0\n",
      "ConvInvolutionBlock-145             [-1, 64, 1, 1]               0\n",
      "          Conv2d-146            [-1, 256, 1, 1]          16,640\n",
      "     BatchNorm2d-147            [-1, 256, 1, 1]             512\n",
      "            SiLU-148            [-1, 256, 1, 1]               0\n",
      "KAN_Convolutional_Layer-149            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-150            [-1, 256, 1, 1]             512\n",
      "          Unfold-151              [-1, 2304, 1]               0\n",
      "          Conv2d-152            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-153            [-1, 128, 1, 1]             256\n",
      "            ReLU-154            [-1, 128, 1, 1]               0\n",
      "          Conv2d-155              [-1, 9, 1, 1]           1,161\n",
      "          Conv2d-156             [-1, 64, 1, 1]          16,448\n",
      "      Involution-157             [-1, 64, 1, 1]               0\n",
      "     BatchNorm2d-158             [-1, 64, 1, 1]             128\n",
      "            SiLU-159             [-1, 64, 1, 1]               0\n",
      "ConvInvolutionBlock-160             [-1, 64, 1, 1]               0\n",
      "          Conv2d-161            [-1, 256, 1, 1]          16,640\n",
      "     BatchNorm2d-162            [-1, 256, 1, 1]             512\n",
      "            SiLU-163            [-1, 256, 1, 1]               0\n",
      "KAN_Convolutional_Layer-164            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-165            [-1, 256, 1, 1]             512\n",
      "          Unfold-166              [-1, 2304, 1]               0\n",
      "          Conv2d-167            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-168            [-1, 128, 1, 1]             256\n",
      "            ReLU-169            [-1, 128, 1, 1]               0\n",
      "          Conv2d-170              [-1, 9, 1, 1]           1,161\n",
      "          Conv2d-171             [-1, 64, 1, 1]          16,448\n",
      "      Involution-172             [-1, 64, 1, 1]               0\n",
      "     BatchNorm2d-173             [-1, 64, 1, 1]             128\n",
      "            SiLU-174             [-1, 64, 1, 1]               0\n",
      "ConvInvolutionBlock-175             [-1, 64, 1, 1]               0\n",
      "          MBConv-176             [-1, 64, 1, 1]               0\n",
      "          Conv2d-177            [-1, 256, 1, 1]          16,640\n",
      "     BatchNorm2d-178            [-1, 256, 1, 1]             512\n",
      "            SiLU-179            [-1, 256, 1, 1]               0\n",
      "KAN_Convolutional_Layer-180            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-181            [-1, 256, 1, 1]             512\n",
      "          Unfold-182              [-1, 2304, 1]               0\n",
      "          Conv2d-183            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-184            [-1, 128, 1, 1]             256\n",
      "            ReLU-185            [-1, 128, 1, 1]               0\n",
      "          Conv2d-186              [-1, 9, 1, 1]           1,161\n",
      "          Conv2d-187            [-1, 128, 1, 1]          32,896\n",
      "      Involution-188            [-1, 128, 1, 1]               0\n",
      "     BatchNorm2d-189            [-1, 128, 1, 1]             256\n",
      "            SiLU-190            [-1, 128, 1, 1]               0\n",
      "ConvInvolutionBlock-191            [-1, 128, 1, 1]               0\n",
      "          Conv2d-192            [-1, 512, 1, 1]          66,048\n",
      "     BatchNorm2d-193            [-1, 512, 1, 1]           1,024\n",
      "            SiLU-194            [-1, 512, 1, 1]               0\n",
      "KAN_Convolutional_Layer-195            [-1, 512, 1, 1]               0\n",
      "     BatchNorm2d-196            [-1, 512, 1, 1]           1,024\n",
      "          Unfold-197              [-1, 4608, 1]               0\n",
      "          Conv2d-198            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-199            [-1, 256, 1, 1]             512\n",
      "            ReLU-200            [-1, 256, 1, 1]               0\n",
      "          Conv2d-201              [-1, 9, 1, 1]           2,313\n",
      "          Conv2d-202            [-1, 128, 1, 1]          65,664\n",
      "      Involution-203            [-1, 128, 1, 1]               0\n",
      "     BatchNorm2d-204            [-1, 128, 1, 1]             256\n",
      "            SiLU-205            [-1, 128, 1, 1]               0\n",
      "ConvInvolutionBlock-206            [-1, 128, 1, 1]               0\n",
      "          Conv2d-207            [-1, 512, 1, 1]          66,048\n",
      "     BatchNorm2d-208            [-1, 512, 1, 1]           1,024\n",
      "            SiLU-209            [-1, 512, 1, 1]               0\n",
      "KAN_Convolutional_Layer-210            [-1, 512, 1, 1]               0\n",
      "     BatchNorm2d-211            [-1, 512, 1, 1]           1,024\n",
      "          Unfold-212              [-1, 4608, 1]               0\n",
      "          Conv2d-213            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-214            [-1, 256, 1, 1]             512\n",
      "            ReLU-215            [-1, 256, 1, 1]               0\n",
      "          Conv2d-216              [-1, 9, 1, 1]           2,313\n",
      "          Conv2d-217            [-1, 128, 1, 1]          65,664\n",
      "      Involution-218            [-1, 128, 1, 1]               0\n",
      "     BatchNorm2d-219            [-1, 128, 1, 1]             256\n",
      "            SiLU-220            [-1, 128, 1, 1]               0\n",
      "ConvInvolutionBlock-221            [-1, 128, 1, 1]               0\n",
      "          Conv2d-222            [-1, 512, 1, 1]          66,048\n",
      "     BatchNorm2d-223            [-1, 512, 1, 1]           1,024\n",
      "            SiLU-224            [-1, 512, 1, 1]               0\n",
      "KAN_Convolutional_Layer-225            [-1, 512, 1, 1]               0\n",
      "     BatchNorm2d-226            [-1, 512, 1, 1]           1,024\n",
      "          Unfold-227              [-1, 4608, 1]               0\n",
      "          Conv2d-228            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-229            [-1, 256, 1, 1]             512\n",
      "            ReLU-230            [-1, 256, 1, 1]               0\n",
      "          Conv2d-231              [-1, 9, 1, 1]           2,313\n",
      "          Conv2d-232            [-1, 128, 1, 1]          65,664\n",
      "      Involution-233            [-1, 128, 1, 1]               0\n",
      "     BatchNorm2d-234            [-1, 128, 1, 1]             256\n",
      "            SiLU-235            [-1, 128, 1, 1]               0\n",
      "ConvInvolutionBlock-236            [-1, 128, 1, 1]               0\n",
      "          Conv2d-237            [-1, 512, 1, 1]          66,048\n",
      "     BatchNorm2d-238            [-1, 512, 1, 1]           1,024\n",
      "            SiLU-239            [-1, 512, 1, 1]               0\n",
      "KAN_Convolutional_Layer-240            [-1, 512, 1, 1]               0\n",
      "     BatchNorm2d-241            [-1, 512, 1, 1]           1,024\n",
      "          Unfold-242              [-1, 4608, 1]               0\n",
      "          Conv2d-243            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-244            [-1, 256, 1, 1]             512\n",
      "            ReLU-245            [-1, 256, 1, 1]               0\n",
      "          Conv2d-246              [-1, 9, 1, 1]           2,313\n",
      "          Conv2d-247            [-1, 128, 1, 1]          65,664\n",
      "      Involution-248            [-1, 128, 1, 1]               0\n",
      "     BatchNorm2d-249            [-1, 128, 1, 1]             256\n",
      "            SiLU-250            [-1, 128, 1, 1]               0\n",
      "ConvInvolutionBlock-251            [-1, 128, 1, 1]               0\n",
      "          MBConv-252            [-1, 128, 1, 1]               0\n",
      "          Conv2d-253            [-1, 768, 1, 1]          99,072\n",
      "     BatchNorm2d-254            [-1, 768, 1, 1]           1,536\n",
      "            SiLU-255            [-1, 768, 1, 1]               0\n",
      "KAN_Convolutional_Layer-256            [-1, 768, 1, 1]               0\n",
      "     BatchNorm2d-257            [-1, 768, 1, 1]           1,536\n",
      "          Unfold-258              [-1, 6912, 1]               0\n",
      "          Conv2d-259            [-1, 384, 1, 1]         295,296\n",
      "     BatchNorm2d-260            [-1, 384, 1, 1]             768\n",
      "            ReLU-261            [-1, 384, 1, 1]               0\n",
      "          Conv2d-262              [-1, 9, 1, 1]           3,465\n",
      "          Conv2d-263            [-1, 160, 1, 1]         123,040\n",
      "      Involution-264            [-1, 160, 1, 1]               0\n",
      "     BatchNorm2d-265            [-1, 160, 1, 1]             320\n",
      "            SiLU-266            [-1, 160, 1, 1]               0\n",
      "ConvInvolutionBlock-267            [-1, 160, 1, 1]               0\n",
      "          Conv2d-268            [-1, 960, 1, 1]         154,560\n",
      "     BatchNorm2d-269            [-1, 960, 1, 1]           1,920\n",
      "            SiLU-270            [-1, 960, 1, 1]               0\n",
      "KAN_Convolutional_Layer-271            [-1, 960, 1, 1]               0\n",
      "     BatchNorm2d-272            [-1, 960, 1, 1]           1,920\n",
      "          Unfold-273              [-1, 8640, 1]               0\n",
      "          Conv2d-274            [-1, 480, 1, 1]         461,280\n",
      "     BatchNorm2d-275            [-1, 480, 1, 1]             960\n",
      "            ReLU-276            [-1, 480, 1, 1]               0\n",
      "          Conv2d-277              [-1, 9, 1, 1]           4,329\n",
      "          Conv2d-278            [-1, 160, 1, 1]         153,760\n",
      "      Involution-279            [-1, 160, 1, 1]               0\n",
      "     BatchNorm2d-280            [-1, 160, 1, 1]             320\n",
      "            SiLU-281            [-1, 160, 1, 1]               0\n",
      "ConvInvolutionBlock-282            [-1, 160, 1, 1]               0\n",
      "          Conv2d-283            [-1, 960, 1, 1]         154,560\n",
      "     BatchNorm2d-284            [-1, 960, 1, 1]           1,920\n",
      "            SiLU-285            [-1, 960, 1, 1]               0\n",
      "KAN_Convolutional_Layer-286            [-1, 960, 1, 1]               0\n",
      "     BatchNorm2d-287            [-1, 960, 1, 1]           1,920\n",
      "          Unfold-288              [-1, 8640, 1]               0\n",
      "          Conv2d-289            [-1, 480, 1, 1]         461,280\n",
      "     BatchNorm2d-290            [-1, 480, 1, 1]             960\n",
      "            ReLU-291            [-1, 480, 1, 1]               0\n",
      "          Conv2d-292              [-1, 9, 1, 1]           4,329\n",
      "          Conv2d-293            [-1, 160, 1, 1]         153,760\n",
      "      Involution-294            [-1, 160, 1, 1]               0\n",
      "     BatchNorm2d-295            [-1, 160, 1, 1]             320\n",
      "            SiLU-296            [-1, 160, 1, 1]               0\n",
      "ConvInvolutionBlock-297            [-1, 160, 1, 1]               0\n",
      "          MBConv-298            [-1, 160, 1, 1]               0\n",
      "          Conv2d-299            [-1, 960, 1, 1]         154,560\n",
      "     BatchNorm2d-300            [-1, 960, 1, 1]           1,920\n",
      "            SiLU-301            [-1, 960, 1, 1]               0\n",
      "KAN_Convolutional_Layer-302            [-1, 960, 1, 1]               0\n",
      "     BatchNorm2d-303            [-1, 960, 1, 1]           1,920\n",
      "          Unfold-304              [-1, 8640, 1]               0\n",
      "          Conv2d-305            [-1, 480, 1, 1]         461,280\n",
      "     BatchNorm2d-306            [-1, 480, 1, 1]             960\n",
      "            ReLU-307            [-1, 480, 1, 1]               0\n",
      "          Conv2d-308              [-1, 9, 1, 1]           4,329\n",
      "          Conv2d-309            [-1, 256, 1, 1]         246,016\n",
      "      Involution-310            [-1, 256, 1, 1]               0\n",
      "     BatchNorm2d-311            [-1, 256, 1, 1]             512\n",
      "            SiLU-312            [-1, 256, 1, 1]               0\n",
      "ConvInvolutionBlock-313            [-1, 256, 1, 1]               0\n",
      "          MBConv-314            [-1, 256, 1, 1]               0\n",
      "         Flatten-315                  [-1, 256]               0\n",
      "          Linear-316                  [-1, 512]         131,584\n",
      "         Dropout-317                  [-1, 512]               0\n",
      "          Linear-318                  [-1, 512]         262,656\n",
      "         Dropout-319                  [-1, 512]               0\n",
      "          Linear-320                 [-1, 1486]         762,318\n",
      "================================================================\n",
      "Total params: 5,754,871\n",
      "Trainable params: 5,754,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 121.99\n",
      "Params size (MB): 21.95\n",
      "Estimated Total Size (MB): 144.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Clear cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optional: Collect garbage (useful if memory is fragmented)\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# Assuming your model is on the GPU\n",
    "# model = efficientnetv2_s(pretrained=False)\n",
    "model = EfficientNetV2S_WithInvolution(num_classes=1486)  # Dynamically set number of classes\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)  # Ensure model is on GPU\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Clear cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optional: Collect garbage (useful if memory is fragmented)\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sashankhravi/miniconda3/envs/birdapp1/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [0/13003], Train Loss: 7.3071\n",
      "Epoch [1/100], Step [500/13003], Train Loss: 7.3005\n",
      "Epoch [1/100], Step [1000/13003], Train Loss: 7.3114\n",
      "Epoch [1/100], Step [1500/13003], Train Loss: 7.3058\n",
      "Epoch [1/100], Step [2000/13003], Train Loss: 7.3137\n",
      "Epoch [1/100], Step [2500/13003], Train Loss: 7.3140\n",
      "Epoch [1/100], Step [3000/13003], Train Loss: 7.3192\n",
      "Epoch [1/100], Step [3500/13003], Train Loss: 7.3005\n",
      "Epoch [1/100], Step [4000/13003], Train Loss: 7.3082\n",
      "Epoch [1/100], Step [4500/13003], Train Loss: 7.3082\n",
      "Epoch [1/100], Step [5000/13003], Train Loss: 7.2998\n",
      "Epoch [1/100], Step [5500/13003], Train Loss: 7.3116\n",
      "Epoch [1/100], Step [6000/13003], Train Loss: 7.3170\n",
      "Epoch [1/100], Step [6500/13003], Train Loss: 7.3039\n",
      "Epoch [1/100], Step [7000/13003], Train Loss: 7.3092\n",
      "Epoch [1/100], Step [7500/13003], Train Loss: 7.2975\n",
      "Epoch [1/100], Step [8000/13003], Train Loss: 7.3053\n",
      "Epoch [1/100], Step [8500/13003], Train Loss: 7.3092\n",
      "Epoch [1/100], Step [9000/13003], Train Loss: 7.3105\n",
      "Epoch [1/100], Step [9500/13003], Train Loss: 7.3062\n",
      "Epoch [1/100], Step [10000/13003], Train Loss: 7.3122\n",
      "Epoch [1/100], Step [10500/13003], Train Loss: 7.3127\n",
      "Epoch [1/100], Step [11000/13003], Train Loss: 7.3116\n",
      "Epoch [1/100], Step [11500/13003], Train Loss: 7.3027\n",
      "Epoch [1/100], Step [12000/13003], Train Loss: 7.3152\n",
      "Epoch [1/100], Step [12500/13003], Train Loss: 7.3066\n",
      "Epoch [1/100], Step [13000/13003], Train Loss: 7.3123\n",
      "Epoch [1/100], Loss: 7.3081, Accuracy: 0.07%\n",
      "Validation Accuracy: 0.07%\n",
      "Epoch [2/100], Step [0/13003], Train Loss: 7.3019\n",
      "Epoch [2/100], Step [500/13003], Train Loss: 7.3085\n",
      "Epoch [2/100], Step [1000/13003], Train Loss: 7.3120\n",
      "Epoch [2/100], Step [1500/13003], Train Loss: 7.3080\n",
      "Epoch [2/100], Step [2000/13003], Train Loss: 7.2978\n",
      "Epoch [2/100], Step [2500/13003], Train Loss: 7.3077\n",
      "Epoch [2/100], Step [3000/13003], Train Loss: 7.3011\n",
      "Epoch [2/100], Step [3500/13003], Train Loss: 7.3152\n",
      "Epoch [2/100], Step [4000/13003], Train Loss: 7.3115\n",
      "Epoch [2/100], Step [4500/13003], Train Loss: 7.3118\n",
      "Epoch [2/100], Step [5000/13003], Train Loss: 7.2902\n",
      "Epoch [2/100], Step [5500/13003], Train Loss: 7.2979\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_run = 1\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128  # Batch size\n",
    "epochs = 100  # Set the number of epochs\n",
    "grad_clip = 1.0  # Maximum gradient norm\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/home/sashankhravi/Datasets/inatbirds100k/train_transformed\"\n",
    "val_dir = \"/home/sashankhravi/Datasets/inatbirds100k/val_transformed\"\n",
    "\n",
    "# Dynamically fetch number of classes from the folder structure (number of subfolders)\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Image resizing and transformation (only resizing to 256x256)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Custom dataset loading\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "# Create DataLoader with the sampler\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize the model (assuming EfficientNetV2SWithInvolution is defined elsewhere)\n",
    "model = EfficientNetV2S_WithInvolution(num_classes=num_classes)  # Dynamically set num_classes\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (e.g., Adam optimizer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the gradient scaler for FP16 precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_train_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using mixed precision (autocast)\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):  # Use autocast for FP16 precision\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient Clipping (before optimizer step)\n",
    "        scaler.unscale_(optimizer)  # Unscale gradients first before clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        # Update the model weights using FP16 gradients and scaling\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_preds += torch.sum(preds == labels)\n",
    "        total_preds += labels.size(0)\n",
    "        \n",
    "        # Print training loss and accuracy every 100 steps\n",
    "        if step % 500 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Step [{step}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Save model checkpoint every 1000 steps\n",
    "        if step % 1000 == 0:\n",
    "            try:\n",
    "                os.makedirs(f\"model_checkpoints_training_run_{training_run}\")\n",
    "            except:\n",
    "                continue\n",
    "            torch.save(model.state_dict(), f\"model_checkpoints_training_run_{training_run}/saved_model_epoch_{epoch}.pth\")\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_preds / total_preds\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):  # Use autocast for FP16 precision\n",
    "                outputs = model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "            # Track accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct_preds / total_preds\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Plot the cumulative training and validation loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", color='blue', marker='o')\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\", color='red', marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cumulative Loss')\n",
    "plt.title('Cumulative Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdapp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
