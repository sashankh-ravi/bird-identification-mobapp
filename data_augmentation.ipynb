{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the transforms for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sashankh-ravi/anaconda3/envs/birdappenv1/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.3' (you have '2.0.2'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "# Custom Fog Effect\n",
    "class AddFog(ImageOnlyTransform):\n",
    "    def __init__(self, p=1.0, fog_intensity=0.5):\n",
    "        super().__init__(p)\n",
    "        self.fog_intensity = fog_intensity\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # Create a white fog overlay (semi-transparent)\n",
    "        fog = np.ones_like(image, dtype=np.uint8) * 255  # White image\n",
    "        fog = cv2.GaussianBlur(fog, (15, 15), 0)  # Slight blur to soften the fog\n",
    "        # Apply some noise to simulate the randomness in fog\n",
    "        noise = np.random.normal(0, 25, fog.shape).astype(np.uint8)\n",
    "        fog = cv2.add(fog, noise)  # Add random noise to the fog\n",
    "\n",
    "        # Blend the fog with the original image\n",
    "        fogged_image = cv2.addWeighted(image, 1 - self.fog_intensity, fog, self.fog_intensity, 0)\n",
    "        return fogged_image\n",
    "\n",
    "# Custom Rain Effect\n",
    "class AddRain(ImageOnlyTransform):\n",
    "    def __init__(self, p=1.0, rain_intensity=0.5, num_drops=100):\n",
    "        super().__init__(p)\n",
    "        self.rain_intensity = rain_intensity\n",
    "        self.num_drops = num_drops\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # Create a copy of the image\n",
    "        rain_image = image.copy()\n",
    "\n",
    "        # Randomly create vertical lines (raindrops)\n",
    "        for _ in range(self.num_drops):\n",
    "            x1 = np.random.randint(0, image.shape[1])\n",
    "            y1 = np.random.randint(0, image.shape[0])\n",
    "            x2 = x1 + np.random.randint(2, 5)  # Small width for raindrops\n",
    "            y2 = y1 + np.random.randint(20, 50)  # Random height for each raindrop\n",
    "\n",
    "            # Draw the raindrop (a vertical line)\n",
    "            cv2.line(rain_image, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "\n",
    "        # Blend the rain image with the original image (based on intensity)\n",
    "        rain_image = cv2.addWeighted(rain_image, 1 - self.rain_intensity, image, self.rain_intensity, 0)\n",
    "        return rain_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, MotionBlur, GaussianBlur, RandomBrightnessContrast\n",
    "from albumentations import RandomGamma, CLAHE, GaussNoise, ElasticTransform, GridDistortion\n",
    "from albumentations import HueSaturationValue, Solarize, CoarseDropout, Resize\n",
    "from albumentations import ChannelShuffle, CenterCrop, Blur, ShiftScaleRotate\n",
    "from albumentations import Perspective, Equalize, InvertImg, ChannelDropout\n",
    "\n",
    "def generate_zooms(base_width, base_height, zoom_levels):\n",
    "    zoom_transforms = [\n",
    "        Compose([\n",
    "            CenterCrop(height=int(base_height / zoom), width=int(base_width / zoom), p=1.0),\n",
    "            MotionBlur(p=0.5, blur_limit=7),  # Additional motion blur per zoom level\n",
    "        ], p=1.0)\n",
    "        for zoom in zoom_levels\n",
    "    ]\n",
    "    return zoom_transforms\n",
    "\n",
    "def transformation_function(zoom_transforms):\n",
    "    transformations = Compose([\n",
    "        # Simulate bird in motion (motion blur)\n",
    "        MotionBlur(p=1.0, blur_limit=7),\n",
    "\n",
    "        # General blur (could represent a shaky or unfocused camera)\n",
    "        GaussianBlur(sigma_limit=(1.0,5.0), blur_limit=(3, 7), p=1.0),\n",
    "\n",
    "        # Zoom transformations (applied one at a time, selected randomly if needed)\n",
    "        *zoom_transforms,\n",
    "\n",
    "        # Rotate and shift the image (simulate slight rotations and camera shake)\n",
    "        ShiftScaleRotate(shift_limit=(-0.3,0.3), scale_limit=(-0.5,0.5), rotate_limit=(-25,25), p=1.0),\n",
    "\n",
    "        # Simulate noisy or poor-quality images (by dropping pixels)\n",
    "        CoarseDropout(hole_height_range=(10, 20), hole_width_range=(10, 50), fill='inpaint_telea', p=1.0),\n",
    "\n",
    "        # Simulate distortion effects (camera shake or image distortions)\n",
    "        ElasticTransform(alpha=10, sigma=30, p=1.0),\n",
    "\n",
    "        # Simulate rapid shifts (shaky camera)\n",
    "        GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "\n",
    "        # Change color tones (lighting conditions, different environments)\n",
    "        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0),\n",
    "\n",
    "        # Standard transformations\n",
    "        Perspective(scale=(0.05, 5), p=1.0),\n",
    "        GaussNoise(std_range=(0.1, 0.35), p=1.0),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "        CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        ChannelShuffle(p=1.0),\n",
    "        Equalize(p=1.0),\n",
    "        Solarize(threshold_range=[0.3, 0.5], p=1.0),\n",
    "        InvertImg(p=1.0),\n",
    "        ChannelDropout(p=1.0),\n",
    "        Blur(blur_limit=7, p=1.0),\n",
    "\n",
    "        # Simulate poor contrast, underexposure, or low-light conditions\n",
    "        RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),\n",
    "\n",
    "        # Custom Fog Effect\n",
    "        AddFog(p=1.0, fog_intensity=0.5),\n",
    "\n",
    "        # Custom Rain Effect\n",
    "        AddRain(p=1.0, rain_intensity=0.5, num_drops=500),\n",
    "    ])\n",
    "    \n",
    "    return transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run transformations for all images in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "# Function to apply each transformation individually and save it\n",
    "def apply_and_save_transformations(image, original_img_path, output_dir, image_label):\n",
    "    # Generate zoom functions and transformations required\n",
    "    base_width, base_height = image.shape[1], image.shape[0]\n",
    "    zoom_levels = [1.5, 2.0, 3.0, 5.0, 7.0, 10.0]\n",
    "    zoom_transforms = generate_zooms(base_width, base_height, zoom_levels)\n",
    "    transformations = transformation_function(zoom_transforms)\n",
    "\n",
    "    for idx, transform in enumerate(transformations):\n",
    "        augmented = transform(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "\n",
    "        # Generate a new filename for the transformed image\n",
    "        filename = f\"{os.path.splitext(os.path.basename(original_img_path))[0]}_transformation_{idx}.jpg\"\n",
    "        output_path = os.path.join(output_dir, image_label, filename)\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Save the transformed image\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "# Directory containing your images (update this to your folder)\n",
    "input_dir = \"/home/sashankh-ravi/Documents/Datasets/iNet_Bird_Small/train\"\n",
    "output_dir = \"/home/sashankh-ravi/Documents/Datasets/iNet_Bird_Small/train_transformed\"\n",
    "\n",
    "# Function to apply transformations in parallel to all images in the dataset\n",
    "def process_images_in_parallel(input_dir, output_dir):\n",
    "    # Iterate through each category (sub-folder) in the training dataset\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "\n",
    "        for category in os.listdir(input_dir):\n",
    "            category_path = os.path.join(input_dir, category)\n",
    "            image_label = category.split(\"/\")[0]\n",
    "\n",
    "            if os.path.isdir(category_path):\n",
    "                # Iterate through each image in the category folder\n",
    "                for img_name in os.listdir(category_path):\n",
    "                    img_path = os.path.join(category_path, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        image = cv2.imread(img_path)\n",
    "\n",
    "                        # apply_and_save_transformations(image, img_path, output_dir, image_label)\n",
    "\n",
    "                        # Submit the image processing task to the executor (parallelize the work)\n",
    "                        futures.append(executor.submit(apply_and_save_transformations, image, img_path, output_dir, image_label))\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            future.result()  # Ensures all transformations are applied and saved\n",
    "\n",
    "# Apply transformations in parallel to all images in the training dataset\n",
    "process_images_in_parallel(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the augmentations for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "# Function to apply each transformation individually and save it\n",
    "def apply_and_save_transformations(image, original_img_path, output_dir, image_label):\n",
    "    # Generate zoom functions and transformations required\n",
    "    base_width, base_height = image.shape[1], image.shape[0]\n",
    "    zoom_levels = [1.5, 2.0, 3.0, 5.0, 7.0, 10.0]\n",
    "    zoom_transforms = generate_zooms(base_width, base_height, zoom_levels)\n",
    "    transformations = transformation_function(zoom_transforms)\n",
    "\n",
    "    for idx, transform in enumerate(transformations):\n",
    "        augmented = transform(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "\n",
    "        # Generate a new filename for the transformed image\n",
    "        filename = f\"{os.path.splitext(os.path.basename(original_img_path))[0]}_transformation_{idx}.jpg\"\n",
    "        output_path = os.path.join(output_dir, image_label, filename)\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Save the transformed image\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "# Directory containing your images (update this to your folder)\n",
    "input_dir = \"/home/sashankh-ravi/Documents/Datasets/iNet_Bird_Small/val\"\n",
    "output_dir = \"/home/sashankh-ravi/Documents/Datasets/iNet_Bird_Small/val_transformed\"\n",
    "\n",
    "# Function to apply transformations in parallel to all images in the dataset\n",
    "def process_images_in_parallel(input_dir, output_dir):\n",
    "    # Iterate through each category (sub-folder) in the training dataset\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "\n",
    "        for category in os.listdir(input_dir):\n",
    "            category_path = os.path.join(input_dir, category)\n",
    "            image_label = category.split(\"/\")[0]\n",
    "\n",
    "            if os.path.isdir(category_path):\n",
    "                # Iterate through each image in the category folder\n",
    "                for img_name in os.listdir(category_path):\n",
    "                    img_path = os.path.join(category_path, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        image = cv2.imread(img_path)\n",
    "\n",
    "                        # apply_and_save_transformations(image, img_path, output_dir, image_label)\n",
    "\n",
    "                        # Submit the image processing task to the executor (parallelize the work)\n",
    "                        futures.append(executor.submit(apply_and_save_transformations, image, img_path, output_dir, image_label))\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            future.result()  # Ensures all transformations are applied and saved\n",
    "\n",
    "# Apply transformations in parallel to all images in the training dataset\n",
    "process_images_in_parallel(input_dir, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdappenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
